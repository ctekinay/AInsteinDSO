# LLM Provider Configuration for Alliander EA Assistant

# Primary LLM provider (groq, openai, ollama)
LLM_PROVIDER=groq

# Groq Configuration (Primary - Free tier available)
# Get your API key from: https://console.groq.com/
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama3-8b-8192
GROQ_MAX_TOKENS=1024
GROQ_TEMPERATURE=0.3
GROQ_TIMEOUT=30
GROQ_RETRIES=3

# OpenAI Configuration (Fallback)
OPENAI_API_KEY=sk-your_openai_api_key_here
OPENAI_MODEL=gpt-3.5-turbo
OPENAI_MAX_TOKENS=1024
OPENAI_TEMPERATURE=0.3
OPENAI_TIMEOUT=30
OPENAI_RETRIES=3

# Ollama Configuration (Local deployment)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=mistral
OLLAMA_MAX_TOKENS=1024
OLLAMA_TEMPERATURE=0.3
OLLAMA_TIMEOUT=60
OLLAMA_RETRIES=3

# Performance Settings
LLM_FALLBACK_ENABLED=true
LLM_HEALTH_CHECK_TIMEOUT=10

# Instructions:
# 1. Copy this file to .env
# 2. Add your Groq API key (free at https://console.groq.com/)
# 3. The system will automatically fall back to template responses if LLM fails
# 4. For queries outside company knowledge, LLM will provide external answers with disclaimers